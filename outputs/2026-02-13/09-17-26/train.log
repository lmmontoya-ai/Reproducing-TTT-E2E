[2026-02-13 09:17:26,819][ttt.train][INFO] - Launching Phase-1 runtime with config:
{'backend': {'backend': 'gpu',
             'compilation_cache_dir': '/tmp/jax_cache',
             'coordinator_address': None,
             'distributed': False,
             'local_device_ids': '0,1,2,3,4,5,6,7',
             'num_devices': 8,
             'num_processes': 1,
             'process_id': 0},
 'checkpoint': {'checkpoint_dir': '/tmp/ext_smoke2/checkpoints/external_smoke2/pretrain-qwen05-fa-import-8K',
                'float_dtype': 'bf16',
                'resume_checkpoint_dir': '/tmp/ext_smoke2/checkpoints/external_smoke2/',
                'save_optimizer_state': True},
 'deploy_paths': {'checkpoint': '/tmp/ext_smoke2/checkpoints',
                  'data': {'books3': '/tmp/phase1_token_data',
                           'dclm_filter_8k': '/tmp/phase1_token_data'}},
 'model': {'attention_pattern': 'full',
           'attn_pdrop': 0.0,
           'bos_token_id': 151643,
           'compute_dtype': 'bf16',
           'embd_pdrop': 0.0,
           'eos_token_id': 151643,
           'feed_forward_prime': 'swiglu',
           'force_flash': True,
           'hidden_size': 896,
           'initializer_range': 0.02,
           'intermediate_size': 4864,
           'mini_batch_size': 8192,
           'name': 'qwen2_5_0_5b',
           'num_attention_heads': 14,
           'num_hidden_layers': 24,
           'num_key_value_heads': 2,
           'output_size': 151936,
           'param_dtype': 'fp32',
           'post_norm': True,
           'pre_norm': True,
           'prime': False,
           'qk_norm': True,
           'remat_attention': '',
           'remat_attention_bwd': '',
           'remat_block': 'nothing_saveable',
           'remat_block_bwd': 'nothing_saveable',
           'remat_mlp': '',
           'remat_mlp_bwd': '',
           'remat_multiple_gd': '',
           'remat_prefix_block': 'nothing_saveable',
           'remat_rms': '',
           'remat_rms_bwd': '',
           'resid_pdrop': 0.0,
           'rms_norm_eps': 1e-06,
           'rope_theta': 1000000.0,
           'seq_len': 32768,
           'seq_modeling_block': 'self_attention',
           'sliding_window_size': 1024,
           'state_dtype': 'fp32',
           'suffix_len': 0,
           'tie_word_embeddings': True,
           'unroll_block_scan': False,
           'unroll_inner_scan': False,
           'vocab_size': 151936},
 'training': {'accum_steps': 1,
              'adapter_recipe': 'none',
              'break_step': -1,
              'checkpoint_path': '/tmp/ext_smoke2/checkpoints',
              'data_seed': 0,
              'data_split': 'train',
              'dataset_name': 'dclm_filter_8k',
              'dataset_path': '/tmp/phase1_token_data',
              'dummy_dataset': True,
              'eval_batch_size': 8,
              'eval_mode': False,
              'eval_split': 'val',
              'exp_dir': '/tmp/ext_smoke2/experiments',
              'exp_folder': 'external_smoke2',
              'exp_name': 'pretrain-qwen05-fa-import-8K',
              'external_model_id': 'Qwen/Qwen2.5-0.5B',
              'external_profile_path': './artifacts/external_models/qwen2_5_0_5b/model_profile.json',
              'global_batch_size': 64,
              'ilr_init': 1.0,
              'ilr_warmup_steps': 1200,
              'init_source': <InitSource.external_hf: 'external_hf'>,
              'inner_remat_freq': 1,
              'load_part': <LoadPart.none: 'none'>,
              'loader_workers': 32,
              'log_wandb': True,
              'model_seed': 0,
              'n_data_parallel': None,
              'n_state_parallel': 1,
              'optimizer_inner': {'b1': '???',
                                  'b2': '???',
                                  'bf16_momentum': '???',
                                  'clip_gradient': 0.0,
                                  'end_lr': '???',
                                  'init_lr': '???',
                                  'lr': 0.01,
                                  'lr_decay_steps': '???',
                                  'lr_warmup_steps': '???',
                                  'optimizer_type': <OptimizerType.sgd: 'sgd'>,
                                  'weight_decay': '???'},
              'optimizer_outer': {'b1': 0.9,
                                  'b2': 0.95,
                                  'bf16_momentum': False,
                                  'clip_gradient': 1.0,
                                  'emb_wd': True,
                                  'end_lr': 1e-05,
                                  'init_lr': 0.0,
                                  'lr': 0.0012,
                                  'lr_decay_steps': 12000,
                                  'lr_warmup_steps': 1200,
                                  'optimizer_type': <OptimizerType.adamw: 'adamw'>,
                                  'weight_decay': 0.1},
              'resume_exp_name': '',
              'resume_step': None,
              'runtime_mode': <RuntimeMode.simulate: 'simulate'>,
              'save_milestone_freq': 1,
              'seq_length': 8192,
              'spec_inner': ['**'],
              'spec_outer': ['**'],
              'tokenizer_name': 'Qwen/Qwen2.5-0.5B',
              'total_steps': 1,
              'train_mode': <TrainMode.pretrain: 'pretrain'>,
              'wandb_entity': 'phase1',
              'wandb_key': 'none',
              'wandb_project': 'phase1'}}
[2026-02-13 09:17:26,825][ttt.train][INFO] - Phase 1 runtime initialized.
[2026-02-13 09:17:26,825][ttt.train][INFO] - run_dir=/tmp/ext_smoke2/experiments/external_smoke2/pretrain-qwen05-fa-import-8K
[2026-02-13 09:17:26,825][ttt.train][INFO] - train_mode=pretrain
[2026-02-13 09:17:26,825][ttt.train][INFO] - dataset_name=dclm_filter_8k
[2026-02-13 09:17:26,825][ttt.train][INFO] - dataset_path=/tmp/phase1_token_data
[2026-02-13 09:17:26,825][ttt.train][INFO] - seq_length=8192
[2026-02-13 09:17:26,825][ttt.train][INFO] - global_batch_size=64
[2026-02-13 09:17:26,825][ttt.train][INFO] - resolved_config=/tmp/ext_smoke2/experiments/external_smoke2/pretrain-qwen05-fa-import-8K/phase1_resolved_config.yaml
[2026-02-13 09:17:26,825][ttt.train][INFO] - runtime_mode=simulate
[2026-02-13 09:17:26,826][ttt.train][INFO] - Phase 1 simulator starting: start_step=0 total_steps=1 model_size_m=527.0 init={'init_source': 'external_hf', 'external_model_id': 'Qwen/Qwen2.5-0.5B', 'external_profile_path': './artifacts/external_models/qwen2_5_0_5b/model_profile.json', 'adapter_recipe': 'none', 'external_profile_status': 'provided'} restore={'load_part': 'none', 'resume_checkpoint_dir': '/tmp/ext_smoke2/checkpoints/external_smoke2', 'resume_exp_name': '', 'init_source': 'external_hf', 'external_model_id': 'Qwen/Qwen2.5-0.5B', 'external_profile_path': './artifacts/external_models/qwen2_5_0_5b/model_profile.json', 'adapter_recipe': 'none', 'external_profile_status': 'provided'}
[2026-02-13 09:17:26,826][ttt.train][INFO] - step=0/1 loss=3.0834 grad_norm=0.6155 lr=1e-06
[2026-02-13 09:17:26,826][ttt.train][INFO] - Saved phase1 checkpoint: /tmp/ext_smoke2/checkpoints/external_smoke2/pretrain-qwen05-fa-import-8K/phase1_ckpt_step_00000000.json
[2026-02-13 09:17:26,826][ttt.train][INFO] - Phase 1 simulator finished in 0.00s; metrics=/tmp/ext_smoke2/experiments/external_smoke2/pretrain-qwen05-fa-import-8K/phase1_metrics.jsonl
[2026-02-13 09:17:26,866][ttt.train][INFO] - Launching Phase-1 runtime with config:
{'backend': {'backend': 'gpu',
             'compilation_cache_dir': '/tmp/jax_cache',
             'coordinator_address': None,
             'distributed': False,
             'local_device_ids': '0,1,2,3,4,5,6,7',
             'num_devices': 8,
             'num_processes': 1,
             'process_id': 0},
 'checkpoint': {'checkpoint_dir': '/tmp/ext_smoke2/checkpoints/external_smoke2/pretrain-smol360-fa-import-8K',
                'float_dtype': 'bf16',
                'resume_checkpoint_dir': '/tmp/ext_smoke2/checkpoints/external_smoke2/',
                'save_optimizer_state': True},
 'deploy_paths': {'checkpoint': '/tmp/ext_smoke2/checkpoints',
                  'data': {'books3': '/tmp/phase1_token_data',
                           'dclm_filter_8k': '/tmp/phase1_token_data'}},
 'model': {'attention_pattern': 'full',
           'attn_pdrop': 0.0,
           'bos_token_id': 0,
           'compute_dtype': 'bf16',
           'embd_pdrop': 0.0,
           'eos_token_id': 0,
           'feed_forward_prime': 'swiglu',
           'force_flash': True,
           'hidden_size': 960,
           'initializer_range': 0.02,
           'intermediate_size': 2560,
           'mini_batch_size': 8192,
           'name': 'smollm2_360m',
           'num_attention_heads': 15,
           'num_hidden_layers': 32,
           'num_key_value_heads': 5,
           'output_size': 49152,
           'param_dtype': 'fp32',
           'post_norm': True,
           'pre_norm': True,
           'prime': False,
           'qk_norm': True,
           'remat_attention': '',
           'remat_attention_bwd': '',
           'remat_block': 'nothing_saveable',
           'remat_block_bwd': 'nothing_saveable',
           'remat_mlp': '',
           'remat_mlp_bwd': '',
           'remat_multiple_gd': '',
           'remat_prefix_block': 'nothing_saveable',
           'remat_rms': '',
           'remat_rms_bwd': '',
           'resid_pdrop': 0.0,
           'rms_norm_eps': 1e-05,
           'rope_theta': 100000.0,
           'seq_len': 32768,
           'seq_modeling_block': 'self_attention',
           'sliding_window_size': 1024,
           'state_dtype': 'fp32',
           'suffix_len': 0,
           'tie_word_embeddings': True,
           'unroll_block_scan': False,
           'unroll_inner_scan': False,
           'vocab_size': 49152},
 'training': {'accum_steps': 1,
              'adapter_recipe': 'none',
              'break_step': -1,
              'checkpoint_path': '/tmp/ext_smoke2/checkpoints',
              'data_seed': 0,
              'data_split': 'train',
              'dataset_name': 'dclm_filter_8k',
              'dataset_path': '/tmp/phase1_token_data',
              'dummy_dataset': True,
              'eval_batch_size': 8,
              'eval_mode': False,
              'eval_split': 'val',
              'exp_dir': '/tmp/ext_smoke2/experiments',
              'exp_folder': 'external_smoke2',
              'exp_name': 'pretrain-smol360-fa-import-8K',
              'external_model_id': 'HuggingFaceTB/SmolLM2-360M',
              'external_profile_path': './artifacts/external_models/smollm2_360m/model_profile.json',
              'global_batch_size': 64,
              'ilr_init': 1.0,
              'ilr_warmup_steps': 960,
              'init_source': <InitSource.external_hf: 'external_hf'>,
              'inner_remat_freq': 1,
              'load_part': <LoadPart.none: 'none'>,
              'loader_workers': 32,
              'log_wandb': True,
              'model_seed': 0,
              'n_data_parallel': None,
              'n_state_parallel': 1,
              'optimizer_inner': {'b1': '???',
                                  'b2': '???',
                                  'bf16_momentum': '???',
                                  'clip_gradient': 0.0,
                                  'end_lr': '???',
                                  'init_lr': '???',
                                  'lr': 0.01,
                                  'lr_decay_steps': '???',
                                  'lr_warmup_steps': '???',
                                  'optimizer_type': <OptimizerType.sgd: 'sgd'>,
                                  'weight_decay': '???'},
              'optimizer_outer': {'b1': 0.9,
                                  'b2': 0.95,
                                  'bf16_momentum': False,
                                  'clip_gradient': 1.0,
                                  'emb_wd': True,
                                  'end_lr': 1e-05,
                                  'init_lr': 0.0,
                                  'lr': 0.0015,
                                  'lr_decay_steps': 9600,
                                  'lr_warmup_steps': 960,
                                  'optimizer_type': <OptimizerType.adamw: 'adamw'>,
                                  'weight_decay': 0.1},
              'resume_exp_name': '',
              'resume_step': None,
              'runtime_mode': <RuntimeMode.simulate: 'simulate'>,
              'save_milestone_freq': 1,
              'seq_length': 8192,
              'spec_inner': ['**'],
              'spec_outer': ['**'],
              'tokenizer_name': 'HuggingFaceTB/SmolLM2-360M',
              'total_steps': 1,
              'train_mode': <TrainMode.pretrain: 'pretrain'>,
              'wandb_entity': 'phase1',
              'wandb_key': 'none',
              'wandb_project': 'phase1'}}
[2026-02-13 09:17:26,871][ttt.train][INFO] - Phase 1 runtime initialized.
[2026-02-13 09:17:26,871][ttt.train][INFO] - run_dir=/tmp/ext_smoke2/experiments/external_smoke2/pretrain-smol360-fa-import-8K
[2026-02-13 09:17:26,871][ttt.train][INFO] - train_mode=pretrain
[2026-02-13 09:17:26,871][ttt.train][INFO] - dataset_name=dclm_filter_8k
[2026-02-13 09:17:26,871][ttt.train][INFO] - dataset_path=/tmp/phase1_token_data
[2026-02-13 09:17:26,871][ttt.train][INFO] - seq_length=8192
[2026-02-13 09:17:26,871][ttt.train][INFO] - global_batch_size=64
[2026-02-13 09:17:26,871][ttt.train][INFO] - resolved_config=/tmp/ext_smoke2/experiments/external_smoke2/pretrain-smol360-fa-import-8K/phase1_resolved_config.yaml
[2026-02-13 09:17:26,871][ttt.train][INFO] - runtime_mode=simulate
[2026-02-13 09:17:26,872][ttt.train][INFO] - Phase 1 simulator starting: start_step=0 total_steps=1 model_size_m=401.1 init={'init_source': 'external_hf', 'external_model_id': 'HuggingFaceTB/SmolLM2-360M', 'external_profile_path': './artifacts/external_models/smollm2_360m/model_profile.json', 'adapter_recipe': 'none', 'external_profile_status': 'provided'} restore={'load_part': 'none', 'resume_checkpoint_dir': '/tmp/ext_smoke2/checkpoints/external_smoke2', 'resume_exp_name': '', 'init_source': 'external_hf', 'external_model_id': 'HuggingFaceTB/SmolLM2-360M', 'external_profile_path': './artifacts/external_models/smollm2_360m/model_profile.json', 'adapter_recipe': 'none', 'external_profile_status': 'provided'}
[2026-02-13 09:17:26,872][ttt.train][INFO] - step=0/1 loss=3.1034 grad_norm=0.6155 lr=1.5625e-06
[2026-02-13 09:17:26,873][ttt.train][INFO] - Saved phase1 checkpoint: /tmp/ext_smoke2/checkpoints/external_smoke2/pretrain-smol360-fa-import-8K/phase1_ckpt_step_00000000.json
[2026-02-13 09:17:26,873][ttt.train][INFO] - Phase 1 simulator finished in 0.00s; metrics=/tmp/ext_smoke2/experiments/external_smoke2/pretrain-smol360-fa-import-8K/phase1_metrics.jsonl
