[2026-02-13 09:15:36,247][ttt.train][INFO] - Launching Phase-1 runtime with config:
{'backend': {'backend': 'gpu',
             'compilation_cache_dir': '/tmp/jax_cache',
             'coordinator_address': None,
             'distributed': False,
             'local_device_ids': '0,1,2,3,4,5,6,7',
             'num_devices': 8,
             'num_processes': 1,
             'process_id': 0},
 'checkpoint': {'checkpoint_dir': '/tmp/ext_smoke_checkpoints/external_smoke/pretrain-qwen05-fa-import-8K',
                'float_dtype': 'bf16',
                'resume_checkpoint_dir': '/tmp/ext_smoke_checkpoints/external_smoke/',
                'save_optimizer_state': True},
 'deploy_paths': {'checkpoint': '/tmp/ext_smoke_checkpoints',
                  'data': {'books3': '/tmp/phase1_token_data',
                           'dclm_filter_8k': '/tmp/phase1_token_data'}},
 'model': {'attention_pattern': 'full',
           'attn_pdrop': 0.0,
           'bos_token_id': 151643,
           'compute_dtype': 'bf16',
           'embd_pdrop': 0.0,
           'eos_token_id': 151643,
           'feed_forward_prime': 'swiglu',
           'force_flash': True,
           'hidden_size': 896,
           'initializer_range': 0.02,
           'intermediate_size': 4864,
           'mini_batch_size': 8192,
           'name': 'qwen2_5_0_5b',
           'num_attention_heads': 14,
           'num_hidden_layers': 24,
           'num_key_value_heads': 2,
           'output_size': 32000,
           'param_dtype': 'fp32',
           'post_norm': True,
           'pre_norm': True,
           'prime': False,
           'qk_norm': True,
           'remat_attention': '',
           'remat_attention_bwd': '',
           'remat_block': 'nothing_saveable',
           'remat_block_bwd': 'nothing_saveable',
           'remat_mlp': '',
           'remat_mlp_bwd': '',
           'remat_multiple_gd': '',
           'remat_prefix_block': 'nothing_saveable',
           'remat_rms': '',
           'remat_rms_bwd': '',
           'resid_pdrop': 0.0,
           'rms_norm_eps': 1e-06,
           'rope_theta': 1000000.0,
           'seq_len': 32768,
           'seq_modeling_block': 'self_attention',
           'sliding_window_size': 1024,
           'state_dtype': 'fp32',
           'suffix_len': 0,
           'tie_word_embeddings': True,
           'unroll_block_scan': False,
           'unroll_inner_scan': False,
           'vocab_size': 151936},
 'training': {'accum_steps': 1,
              'adapter_recipe': 'none',
              'break_step': -1,
              'checkpoint_path': '/tmp/ext_smoke_checkpoints',
              'data_seed': 0,
              'data_split': 'train',
              'dataset_name': 'dclm_filter_8k',
              'dataset_path': '/tmp/phase1_token_data',
              'dummy_dataset': True,
              'eval_batch_size': 8,
              'eval_mode': False,
              'eval_split': 'val',
              'exp_dir': '/tmp/ext_smoke_experiments',
              'exp_folder': 'external_smoke',
              'exp_name': 'pretrain-qwen05-fa-import-8K',
              'external_model_id': 'Qwen/Qwen2.5-0.5B',
              'external_profile_path': '/tmp/ext_smoke_checkpoints/external_models/qwen2_5_0_5b/model_profile.json',
              'global_batch_size': 64,
              'ilr_init': 1.0,
              'ilr_warmup_steps': 1200,
              'init_source': <InitSource.external_hf: 'external_hf'>,
              'inner_remat_freq': 1,
              'load_part': <LoadPart.none: 'none'>,
              'loader_workers': 32,
              'log_wandb': True,
              'model_seed': 0,
              'n_data_parallel': None,
              'n_state_parallel': 1,
              'optimizer_inner': {'b1': '???',
                                  'b2': '???',
                                  'bf16_momentum': '???',
                                  'clip_gradient': 0.0,
                                  'end_lr': '???',
                                  'init_lr': '???',
                                  'lr': 0.01,
                                  'lr_decay_steps': '???',
                                  'lr_warmup_steps': '???',
                                  'optimizer_type': <OptimizerType.sgd: 'sgd'>,
                                  'weight_decay': '???'},
              'optimizer_outer': {'b1': 0.9,
                                  'b2': 0.95,
                                  'bf16_momentum': False,
                                  'clip_gradient': 1.0,
                                  'emb_wd': True,
                                  'end_lr': 1e-05,
                                  'init_lr': 0.0,
                                  'lr': 0.0012,
                                  'lr_decay_steps': 12000,
                                  'lr_warmup_steps': 1200,
                                  'optimizer_type': <OptimizerType.adamw: 'adamw'>,
                                  'weight_decay': 0.1},
              'resume_exp_name': '',
              'resume_step': None,
              'runtime_mode': <RuntimeMode.simulate: 'simulate'>,
              'save_milestone_freq': 1,
              'seq_length': 8192,
              'spec_inner': ['**'],
              'spec_outer': ['**'],
              'tokenizer_name': 'meta-llama/Llama-2-7b-hf',
              'total_steps': 1,
              'train_mode': <TrainMode.pretrain: 'pretrain'>,
              'wandb_entity': 'phase1',
              'wandb_key': 'none',
              'wandb_project': 'phase1'}}
[2026-02-13 09:15:36,252][ttt.train][INFO] - Phase 1 runtime initialized.
[2026-02-13 09:15:36,252][ttt.train][INFO] - run_dir=/tmp/ext_smoke_experiments/external_smoke/pretrain-qwen05-fa-import-8K
[2026-02-13 09:15:36,252][ttt.train][INFO] - train_mode=pretrain
[2026-02-13 09:15:36,252][ttt.train][INFO] - dataset_name=dclm_filter_8k
[2026-02-13 09:15:36,252][ttt.train][INFO] - dataset_path=/tmp/phase1_token_data
[2026-02-13 09:15:36,252][ttt.train][INFO] - seq_length=8192
[2026-02-13 09:15:36,252][ttt.train][INFO] - global_batch_size=64
[2026-02-13 09:15:36,252][ttt.train][INFO] - resolved_config=/tmp/ext_smoke_experiments/external_smoke/pretrain-qwen05-fa-import-8K/phase1_resolved_config.yaml
[2026-02-13 09:15:36,252][ttt.train][INFO] - runtime_mode=simulate
[2026-02-13 09:15:36,253][ttt.train][INFO] - Phase 1 simulator starting: start_step=0 total_steps=1 model_size_m=527.0 init={'init_source': 'external_hf', 'external_model_id': 'Qwen/Qwen2.5-0.5B', 'external_profile_path': '/tmp/ext_smoke_checkpoints/external_models/qwen2_5_0_5b/model_profile.json', 'adapter_recipe': 'none', 'external_profile_status': 'provided'} restore={'load_part': 'none', 'resume_checkpoint_dir': '/tmp/ext_smoke_checkpoints/external_smoke', 'resume_exp_name': '', 'init_source': 'external_hf', 'external_model_id': 'Qwen/Qwen2.5-0.5B', 'external_profile_path': '/tmp/ext_smoke_checkpoints/external_models/qwen2_5_0_5b/model_profile.json', 'adapter_recipe': 'none', 'external_profile_status': 'provided'}
[2026-02-13 09:15:36,254][ttt.train][INFO] - step=0/1 loss=3.0834 grad_norm=0.6155 lr=1e-06
[2026-02-13 09:15:36,254][ttt.train][INFO] - Saved phase1 checkpoint: /tmp/ext_smoke_checkpoints/external_smoke/pretrain-qwen05-fa-import-8K/phase1_ckpt_step_00000000.json
[2026-02-13 09:15:36,254][ttt.train][INFO] - Phase 1 simulator finished in 0.00s; metrics=/tmp/ext_smoke_experiments/external_smoke/pretrain-qwen05-fa-import-8K/phase1_metrics.jsonl
[2026-02-13 09:15:36,490][ttt.train][INFO] - Launching Phase-1 runtime with config:
{'backend': {'backend': 'gpu',
             'compilation_cache_dir': '/tmp/jax_cache',
             'coordinator_address': None,
             'distributed': False,
             'local_device_ids': '0,1,2,3,4,5,6,7',
             'num_devices': 8,
             'num_processes': 1,
             'process_id': 0},
 'checkpoint': {'checkpoint_dir': '/tmp/ext_smoke_checkpoints/external_smoke/pretrain-qwen05-fa-scratch-8K',
                'float_dtype': 'bf16',
                'resume_checkpoint_dir': '/tmp/ext_smoke_checkpoints/external_smoke/',
                'save_optimizer_state': True},
 'deploy_paths': {'checkpoint': '/tmp/ext_smoke_checkpoints',
                  'data': {'books3': '/tmp/phase1_token_data',
                           'dclm_filter_8k': '/tmp/phase1_token_data'}},
 'model': {'attention_pattern': 'full',
           'attn_pdrop': 0.0,
           'bos_token_id': 151643,
           'compute_dtype': 'bf16',
           'embd_pdrop': 0.0,
           'eos_token_id': 151643,
           'feed_forward_prime': 'swiglu',
           'force_flash': True,
           'hidden_size': 896,
           'initializer_range': 0.02,
           'intermediate_size': 4864,
           'mini_batch_size': 8192,
           'name': 'qwen2_5_0_5b',
           'num_attention_heads': 14,
           'num_hidden_layers': 24,
           'num_key_value_heads': 2,
           'output_size': 32000,
           'param_dtype': 'fp32',
           'post_norm': True,
           'pre_norm': True,
           'prime': False,
           'qk_norm': True,
           'remat_attention': '',
           'remat_attention_bwd': '',
           'remat_block': 'nothing_saveable',
           'remat_block_bwd': 'nothing_saveable',
           'remat_mlp': '',
           'remat_mlp_bwd': '',
           'remat_multiple_gd': '',
           'remat_prefix_block': 'nothing_saveable',
           'remat_rms': '',
           'remat_rms_bwd': '',
           'resid_pdrop': 0.0,
           'rms_norm_eps': 1e-06,
           'rope_theta': 1000000.0,
           'seq_len': 32768,
           'seq_modeling_block': 'self_attention',
           'sliding_window_size': 1024,
           'state_dtype': 'fp32',
           'suffix_len': 0,
           'tie_word_embeddings': True,
           'unroll_block_scan': False,
           'unroll_inner_scan': False,
           'vocab_size': 151936},
 'training': {'accum_steps': 1,
              'adapter_recipe': 'none',
              'break_step': -1,
              'checkpoint_path': '/tmp/ext_smoke_checkpoints',
              'data_seed': 0,
              'data_split': 'train',
              'dataset_name': 'dclm_filter_8k',
              'dataset_path': '/tmp/phase1_token_data',
              'dummy_dataset': True,
              'eval_batch_size': 8,
              'eval_mode': False,
              'eval_split': 'val',
              'exp_dir': '/tmp/ext_smoke_experiments',
              'exp_folder': 'external_smoke',
              'exp_name': 'pretrain-qwen05-fa-scratch-8K',
              'external_model_id': '',
              'external_profile_path': '',
              'global_batch_size': 64,
              'ilr_init': 1.0,
              'ilr_warmup_steps': 1200,
              'init_source': <InitSource.scratch: 'scratch'>,
              'inner_remat_freq': 1,
              'load_part': <LoadPart.none: 'none'>,
              'loader_workers': 32,
              'log_wandb': True,
              'model_seed': 0,
              'n_data_parallel': None,
              'n_state_parallel': 1,
              'optimizer_inner': {'b1': '???',
                                  'b2': '???',
                                  'bf16_momentum': '???',
                                  'clip_gradient': 0.0,
                                  'end_lr': '???',
                                  'init_lr': '???',
                                  'lr': 0.01,
                                  'lr_decay_steps': '???',
                                  'lr_warmup_steps': '???',
                                  'optimizer_type': <OptimizerType.sgd: 'sgd'>,
                                  'weight_decay': '???'},
              'optimizer_outer': {'b1': 0.9,
                                  'b2': 0.95,
                                  'bf16_momentum': False,
                                  'clip_gradient': 1.0,
                                  'emb_wd': True,
                                  'end_lr': 1e-05,
                                  'init_lr': 0.0,
                                  'lr': 0.0012,
                                  'lr_decay_steps': 12000,
                                  'lr_warmup_steps': 1200,
                                  'optimizer_type': <OptimizerType.adamw: 'adamw'>,
                                  'weight_decay': 0.1},
              'resume_exp_name': '',
              'resume_step': None,
              'runtime_mode': <RuntimeMode.simulate: 'simulate'>,
              'save_milestone_freq': 1,
              'seq_length': 8192,
              'spec_inner': ['**'],
              'spec_outer': ['**'],
              'tokenizer_name': 'meta-llama/Llama-2-7b-hf',
              'total_steps': 1,
              'train_mode': <TrainMode.pretrain: 'pretrain'>,
              'wandb_entity': 'phase1',
              'wandb_key': 'none',
              'wandb_project': 'phase1'}}
[2026-02-13 09:15:36,495][ttt.train][INFO] - Phase 1 runtime initialized.
[2026-02-13 09:15:36,495][ttt.train][INFO] - run_dir=/tmp/ext_smoke_experiments/external_smoke/pretrain-qwen05-fa-scratch-8K
[2026-02-13 09:15:36,495][ttt.train][INFO] - train_mode=pretrain
[2026-02-13 09:15:36,495][ttt.train][INFO] - dataset_name=dclm_filter_8k
[2026-02-13 09:15:36,495][ttt.train][INFO] - dataset_path=/tmp/phase1_token_data
[2026-02-13 09:15:36,495][ttt.train][INFO] - seq_length=8192
[2026-02-13 09:15:36,495][ttt.train][INFO] - global_batch_size=64
[2026-02-13 09:15:36,495][ttt.train][INFO] - resolved_config=/tmp/ext_smoke_experiments/external_smoke/pretrain-qwen05-fa-scratch-8K/phase1_resolved_config.yaml
[2026-02-13 09:15:36,495][ttt.train][INFO] - runtime_mode=simulate
[2026-02-13 09:15:36,496][ttt.train][INFO] - Phase 1 simulator starting: start_step=0 total_steps=1 model_size_m=527.0 init={'init_source': 'scratch', 'external_model_id': '', 'external_profile_path': '', 'adapter_recipe': 'none'} restore={'load_part': 'none', 'resume_checkpoint_dir': '/tmp/ext_smoke_checkpoints/external_smoke', 'resume_exp_name': '', 'init_source': 'scratch', 'external_model_id': '', 'external_profile_path': '', 'adapter_recipe': 'none'}
[2026-02-13 09:15:36,496][ttt.train][INFO] - step=0/1 loss=3.0834 grad_norm=0.6155 lr=1e-06
[2026-02-13 09:15:36,496][ttt.train][INFO] - Saved phase1 checkpoint: /tmp/ext_smoke_checkpoints/external_smoke/pretrain-qwen05-fa-scratch-8K/phase1_ckpt_step_00000000.json
[2026-02-13 09:15:36,496][ttt.train][INFO] - Phase 1 simulator finished in 0.00s; metrics=/tmp/ext_smoke_experiments/external_smoke/pretrain-qwen05-fa-scratch-8K/phase1_metrics.jsonl
[2026-02-13 09:15:36,734][ttt.train][INFO] - Launching Phase-1 runtime with config:
{'backend': {'backend': 'gpu',
             'compilation_cache_dir': '/tmp/jax_cache',
             'coordinator_address': None,
             'distributed': False,
             'local_device_ids': '0,1,2,3,4,5,6,7',
             'num_devices': 8,
             'num_processes': 1,
             'process_id': 0},
 'checkpoint': {'checkpoint_dir': '/tmp/ext_smoke_checkpoints/external_smoke/adapt-smol360-e2e-8K-from-import',
                'float_dtype': 'bf16',
                'resume_checkpoint_dir': '/tmp/ext_smoke_checkpoints/external_smoke/adapt-smol360-swa-8K-from-import',
                'save_optimizer_state': True},
 'deploy_paths': {'checkpoint': '/tmp/ext_smoke_checkpoints',
                  'data': {'books3': '/tmp/phase1_token_data',
                           'dclm_filter_8k': '/tmp/phase1_token_data'}},
 'model': {'attention_pattern': 'ttt_swa',
           'attn_pdrop': 0.0,
           'bos_token_id': 0,
           'compute_dtype': 'bf16',
           'embd_pdrop': 0.0,
           'eos_token_id': 0,
           'feed_forward_prime': 'swiglu',
           'force_flash': False,
           'hidden_size': 960,
           'initializer_range': 0.02,
           'intermediate_size': 2560,
           'mini_batch_size': 1024,
           'name': 'smollm2_360m',
           'num_attention_heads': 15,
           'num_hidden_layers': 32,
           'num_key_value_heads': 5,
           'output_size': 32000,
           'param_dtype': 'fp32',
           'post_norm': True,
           'pre_norm': True,
           'prime': True,
           'qk_norm': True,
           'remat_attention': '',
           'remat_attention_bwd': '',
           'remat_block': '',
           'remat_block_bwd': '',
           'remat_mlp': '',
           'remat_mlp_bwd': '',
           'remat_multiple_gd': '',
           'remat_prefix_block': 'nothing_saveable',
           'remat_rms': '',
           'remat_rms_bwd': '',
           'resid_pdrop': 0.0,
           'rms_norm_eps': 1e-05,
           'rope_theta': 100000.0,
           'seq_len': 32768,
           'seq_modeling_block': 'SWA',
           'sliding_window_size': 4096,
           'state_dtype': 'fp32',
           'suffix_len': 6,
           'tie_word_embeddings': True,
           'unroll_block_scan': True,
           'unroll_inner_scan': False,
           'vocab_size': 49152},
 'training': {'accum_steps': 1,
              'adapter_recipe': 'ttt_bridge',
              'break_step': -1,
              'checkpoint_path': '/tmp/ext_smoke_checkpoints',
              'data_seed': 0,
              'data_split': 'train',
              'dataset_name': 'dclm_filter_8k',
              'dataset_path': '/tmp/phase1_token_data',
              'dummy_dataset': True,
              'eval_batch_size': 8,
              'eval_mode': False,
              'eval_split': 'val',
              'exp_dir': '/tmp/ext_smoke_experiments',
              'exp_folder': 'external_smoke',
              'exp_name': 'adapt-smol360-e2e-8K-from-import',
              'external_model_id': 'HuggingFaceTB/SmolLM2-360M',
              'external_profile_path': '/tmp/ext_smoke_checkpoints/external_models/smollm2_360m/model_profile.json',
              'global_batch_size': 64,
              'ilr_init': 0.1,
              'ilr_warmup_steps': 960,
              'init_source': <InitSource.external_hf: 'external_hf'>,
              'inner_remat_freq': 1,
              'load_part': <LoadPart.params: 'params'>,
              'loader_workers': 32,
              'log_wandb': True,
              'model_seed': 0,
              'n_data_parallel': None,
              'n_state_parallel': 1,
              'optimizer_inner': {'b1': '???',
                                  'b2': '???',
                                  'bf16_momentum': '???',
                                  'clip_gradient': 1.0,
                                  'end_lr': '???',
                                  'init_lr': '???',
                                  'lr': 1.0,
                                  'lr_decay_steps': '???',
                                  'lr_warmup_steps': '???',
                                  'optimizer_type': <OptimizerType.sgd: 'sgd'>,
                                  'weight_decay': '???'},
              'optimizer_outer': {'b1': 0.9,
                                  'b2': 0.95,
                                  'bf16_momentum': False,
                                  'clip_gradient': 1.0,
                                  'emb_wd': True,
                                  'end_lr': 1e-05,
                                  'init_lr': 0.0,
                                  'lr': 0.0015,
                                  'lr_decay_steps': 9600,
                                  'lr_warmup_steps': 960,
                                  'optimizer_type': <OptimizerType.adamw: 'adamw'>,
                                  'weight_decay': 0.1},
              'resume_exp_name': 'adapt-smol360-swa-8K-from-import',
              'resume_step': None,
              'runtime_mode': <RuntimeMode.simulate: 'simulate'>,
              'save_milestone_freq': 1,
              'seq_length': 8192,
              'spec_inner': ['language_model.**.suffix_blocks.feed_forward_prime.**'],
              'spec_outer': ['**'],
              'tokenizer_name': 'meta-llama/Llama-2-7b-hf',
              'total_steps': 1,
              'train_mode': <TrainMode.meta: 'meta'>,
              'wandb_entity': 'phase1',
              'wandb_key': 'none',
              'wandb_project': 'phase1'}}
[2026-02-13 09:15:36,739][ttt.train][INFO] - Phase 1 runtime initialized.
[2026-02-13 09:15:36,739][ttt.train][INFO] - run_dir=/tmp/ext_smoke_experiments/external_smoke/adapt-smol360-e2e-8K-from-import
[2026-02-13 09:15:36,739][ttt.train][INFO] - train_mode=meta
[2026-02-13 09:15:36,739][ttt.train][INFO] - dataset_name=dclm_filter_8k
[2026-02-13 09:15:36,739][ttt.train][INFO] - dataset_path=/tmp/phase1_token_data
[2026-02-13 09:15:36,739][ttt.train][INFO] - seq_length=8192
[2026-02-13 09:15:36,739][ttt.train][INFO] - global_batch_size=64
[2026-02-13 09:15:36,739][ttt.train][INFO] - resolved_config=/tmp/ext_smoke_experiments/external_smoke/adapt-smol360-e2e-8K-from-import/phase1_resolved_config.yaml
[2026-02-13 09:15:36,739][ttt.train][INFO] - runtime_mode=simulate
[2026-02-13 09:15:36,740][ttt.train][INFO] - Phase 1 simulator starting: start_step=0 total_steps=1 model_size_m=401.1 init={'init_source': 'external_hf', 'external_model_id': 'HuggingFaceTB/SmolLM2-360M', 'external_profile_path': '/tmp/ext_smoke_checkpoints/external_models/smollm2_360m/model_profile.json', 'adapter_recipe': 'ttt_bridge', 'external_profile_status': 'provided'} restore={'load_part': 'params', 'resume_checkpoint_dir': '/tmp/ext_smoke_checkpoints/external_smoke/adapt-smol360-swa-8K-from-import', 'resume_exp_name': 'adapt-smol360-swa-8K-from-import', 'init_source': 'external_hf', 'external_model_id': 'HuggingFaceTB/SmolLM2-360M', 'external_profile_path': '/tmp/ext_smoke_checkpoints/external_models/smollm2_360m/model_profile.json', 'adapter_recipe': 'ttt_bridge', 'external_profile_status': 'provided', 'restore_status': 'missing_checkpoint'}
[2026-02-13 09:15:36,740][ttt.train][INFO] - step=0/1 loss=2.9534 grad_norm=0.6155 lr=1.5625e-06
[2026-02-13 09:15:36,741][ttt.train][INFO] - Saved phase1 checkpoint: /tmp/ext_smoke_checkpoints/external_smoke/adapt-smol360-e2e-8K-from-import/phase1_ckpt_step_00000000.json
[2026-02-13 09:15:36,741][ttt.train][INFO] - Phase 1 simulator finished in 0.00s; metrics=/tmp/ext_smoke_experiments/external_smoke/adapt-smol360-e2e-8K-from-import/phase1_metrics.jsonl
[2026-02-13 09:15:36,976][ttt.train][INFO] - Launching Phase-1 runtime with config:
{'backend': {'backend': 'gpu',
             'compilation_cache_dir': '/tmp/jax_cache',
             'coordinator_address': None,
             'distributed': False,
             'local_device_ids': '0,1,2,3,4,5,6,7',
             'num_devices': 8,
             'num_processes': 1,
             'process_id': 0},
 'checkpoint': {'checkpoint_dir': '/tmp/ext_smoke_checkpoints/external_smoke/adapt-smol360-swa-8K-from-import',
                'float_dtype': 'bf16',
                'resume_checkpoint_dir': '/tmp/ext_smoke_checkpoints/external_smoke/pretrain-smol360-fa-import-8K',
                'save_optimizer_state': True},
 'deploy_paths': {'checkpoint': '/tmp/ext_smoke_checkpoints',
                  'data': {'books3': '/tmp/phase1_token_data',
                           'dclm_filter_8k': '/tmp/phase1_token_data'}},
 'model': {'attention_pattern': 'swa',
           'attn_pdrop': 0.0,
           'bos_token_id': 0,
           'compute_dtype': 'bf16',
           'embd_pdrop': 0.0,
           'eos_token_id': 0,
           'feed_forward_prime': 'swiglu',
           'force_flash': False,
           'hidden_size': 960,
           'initializer_range': 0.02,
           'intermediate_size': 2560,
           'mini_batch_size': 2048,
           'name': 'smollm2_360m',
           'num_attention_heads': 15,
           'num_hidden_layers': 32,
           'num_key_value_heads': 5,
           'output_size': 32000,
           'param_dtype': 'fp32',
           'post_norm': True,
           'pre_norm': True,
           'prime': False,
           'qk_norm': True,
           'remat_attention': '',
           'remat_attention_bwd': '',
           'remat_block': '',
           'remat_block_bwd': '',
           'remat_mlp': '',
           'remat_mlp_bwd': '',
           'remat_multiple_gd': '',
           'remat_prefix_block': 'nothing_saveable',
           'remat_rms': '',
           'remat_rms_bwd': '',
           'resid_pdrop': 0.0,
           'rms_norm_eps': 1e-05,
           'rope_theta': 100000.0,
           'seq_len': 32768,
           'seq_modeling_block': 'SWA',
           'sliding_window_size': 4096,
           'state_dtype': 'fp32',
           'suffix_len': 0,
           'tie_word_embeddings': True,
           'unroll_block_scan': True,
           'unroll_inner_scan': False,
           'vocab_size': 49152},
 'training': {'accum_steps': 1,
              'adapter_recipe': 'swa_bridge',
              'break_step': -1,
              'checkpoint_path': '/tmp/ext_smoke_checkpoints',
              'data_seed': 0,
              'data_split': 'train',
              'dataset_name': 'dclm_filter_8k',
              'dataset_path': '/tmp/phase1_token_data',
              'dummy_dataset': True,
              'eval_batch_size': 8,
              'eval_mode': False,
              'eval_split': 'val',
              'exp_dir': '/tmp/ext_smoke_experiments',
              'exp_folder': 'external_smoke',
              'exp_name': 'adapt-smol360-swa-8K-from-import',
              'external_model_id': 'HuggingFaceTB/SmolLM2-360M',
              'external_profile_path': '/tmp/ext_smoke_checkpoints/external_models/smollm2_360m/model_profile.json',
              'global_batch_size': 64,
              'ilr_init': 1.0,
              'ilr_warmup_steps': 960,
              'init_source': <InitSource.external_hf: 'external_hf'>,
              'inner_remat_freq': 1,
              'load_part': <LoadPart.params: 'params'>,
              'loader_workers': 32,
              'log_wandb': True,
              'model_seed': 0,
              'n_data_parallel': None,
              'n_state_parallel': 1,
              'optimizer_inner': {'b1': '???',
                                  'b2': '???',
                                  'bf16_momentum': '???',
                                  'clip_gradient': 0.0,
                                  'end_lr': '???',
                                  'init_lr': '???',
                                  'lr': 0.01,
                                  'lr_decay_steps': '???',
                                  'lr_warmup_steps': '???',
                                  'optimizer_type': <OptimizerType.sgd: 'sgd'>,
                                  'weight_decay': '???'},
              'optimizer_outer': {'b1': 0.9,
                                  'b2': 0.95,
                                  'bf16_momentum': False,
                                  'clip_gradient': 1.0,
                                  'emb_wd': True,
                                  'end_lr': 1e-05,
                                  'init_lr': 0.0,
                                  'lr': 0.0015,
                                  'lr_decay_steps': 9600,
                                  'lr_warmup_steps': 960,
                                  'optimizer_type': <OptimizerType.adamw: 'adamw'>,
                                  'weight_decay': 0.1},
              'resume_exp_name': 'pretrain-smol360-fa-import-8K',
              'resume_step': None,
              'runtime_mode': <RuntimeMode.simulate: 'simulate'>,
              'save_milestone_freq': 1,
              'seq_length': 8192,
              'spec_inner': ['**'],
              'spec_outer': ['**'],
              'tokenizer_name': 'meta-llama/Llama-2-7b-hf',
              'total_steps': 1,
              'train_mode': <TrainMode.pretrain: 'pretrain'>,
              'wandb_entity': 'phase1',
              'wandb_key': 'none',
              'wandb_project': 'phase1'}}
[2026-02-13 09:15:36,981][ttt.train][INFO] - Phase 1 runtime initialized.
[2026-02-13 09:15:36,981][ttt.train][INFO] - run_dir=/tmp/ext_smoke_experiments/external_smoke/adapt-smol360-swa-8K-from-import
[2026-02-13 09:15:36,981][ttt.train][INFO] - train_mode=pretrain
[2026-02-13 09:15:36,981][ttt.train][INFO] - dataset_name=dclm_filter_8k
[2026-02-13 09:15:36,981][ttt.train][INFO] - dataset_path=/tmp/phase1_token_data
[2026-02-13 09:15:36,981][ttt.train][INFO] - seq_length=8192
[2026-02-13 09:15:36,981][ttt.train][INFO] - global_batch_size=64
[2026-02-13 09:15:36,981][ttt.train][INFO] - resolved_config=/tmp/ext_smoke_experiments/external_smoke/adapt-smol360-swa-8K-from-import/phase1_resolved_config.yaml
[2026-02-13 09:15:36,982][ttt.train][INFO] - runtime_mode=simulate
[2026-02-13 09:15:36,982][ttt.train][INFO] - Phase 1 simulator starting: start_step=0 total_steps=1 model_size_m=401.1 init={'init_source': 'external_hf', 'external_model_id': 'HuggingFaceTB/SmolLM2-360M', 'external_profile_path': '/tmp/ext_smoke_checkpoints/external_models/smollm2_360m/model_profile.json', 'adapter_recipe': 'swa_bridge', 'external_profile_status': 'provided'} restore={'load_part': 'params', 'resume_checkpoint_dir': '/tmp/ext_smoke_checkpoints/external_smoke/pretrain-smol360-fa-import-8K', 'resume_exp_name': 'pretrain-smol360-fa-import-8K', 'init_source': 'external_hf', 'external_model_id': 'HuggingFaceTB/SmolLM2-360M', 'external_profile_path': '/tmp/ext_smoke_checkpoints/external_models/smollm2_360m/model_profile.json', 'adapter_recipe': 'swa_bridge', 'external_profile_status': 'provided', 'restore_status': 'missing_checkpoint'}
[2026-02-13 09:15:36,983][ttt.train][INFO] - step=0/1 loss=3.1034 grad_norm=0.6155 lr=1.5625e-06
[2026-02-13 09:15:36,983][ttt.train][INFO] - Saved phase1 checkpoint: /tmp/ext_smoke_checkpoints/external_smoke/adapt-smol360-swa-8K-from-import/phase1_ckpt_step_00000000.json
[2026-02-13 09:15:36,983][ttt.train][INFO] - Phase 1 simulator finished in 0.00s; metrics=/tmp/ext_smoke_experiments/external_smoke/adapt-smol360-swa-8K-from-import/phase1_metrics.jsonl
