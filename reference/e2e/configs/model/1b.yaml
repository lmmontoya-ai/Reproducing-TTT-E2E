defaults:
  - base_model

name: 1b
vocab_size: 128256
bos_token_id: 128000
eos_token_id: 128001
num_hidden_layers: 24
hidden_size: 2048
num_attention_heads: 32
intermediate_size: 5376
initializer_range: 0.02
rms_norm_eps: 1e-6
tie_word_embeddings: True
