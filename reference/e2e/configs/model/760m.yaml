defaults:
  - base_model

name: 760m
vocab_size: 128256
bos_token_id: 128000
eos_token_id: 128001
num_hidden_layers: 24
hidden_size: 1536
num_attention_heads: 16
intermediate_size: 4096
initializer_range: 0.02
rms_norm_eps: 1e-6
tie_word_embeddings: True
